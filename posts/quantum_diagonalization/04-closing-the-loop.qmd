---
title: "Closing the Loop: From Fixed Angles to Optimization"
date: 2025-12-12
categories: [Quantum Computing, VQE, Optimization]
image: img/landscape_optimization.png
description: "Turning constants into variables: How to build a parameterized quantum circuit and use classical optimization to find the minimum eigenvalue and eigenvector."
format:
  html:
    code-fold: show
execute:
  enabled: true
  freeze: false
  keep-ipynb: true
jupyter: quantum
draft: true
---

In our [last post](./03-encoding-math-into-metal.qmd), we successfully calculated the value $v^T A v$ for a *specific* vector $v$. We manually rotated our qubits by specific angles ($\pi/3$ and $\pi/4$), ran the Estimator, and verified that the result matched our classical calculation.

But in a real problem, we don't know the answer ahead of time. We don't know the specific angles that create the solution. We are searching for the **minimum eigenvalue** ($\lambda_0$) and its corresponding **eigenvector** ($x_0$).

To find them, we must transition from a static calculation to a dynamic **optimization loop**.

## 1. The Hybrid Loop

The quantum computer cannot "find" the minimum on its own. It is just a very expensive function evaluator. It takes a set of angles $\vec{\theta}$ and returns a cost $E$. The logic for *how* to change $\vec{\theta}$ to lower the cost lives on the classical computer.

This creates a hybrid feedback loop:

1.  **Classical CPU:** Guesses a set of parameters $\vec{\theta}$ (e.g., $[0, 0]$).
2.  **Quantum QPU (Estimator):** Prepares the state $|v(\vec{\theta})\rangle$ and measures the expectation value $E = \langle v(\vec{\theta}) | A | v(\vec{\theta}) \rangle$.
3.  **Classical CPU:** Looks at $E$. Is it lower than before?
    * *Yes:* Move further in that direction.
    * *No:* Try a different direction.
4.  **Repeat** until the value converges to the minimum.

## 2. Step A: Finding the Minimum Eigenvalue

Let's make this concrete. We will use the **exact same matrix and circuit** from the previous post.
The only difference: Last time, we hard-coded `np.pi/3`. This time, we will insert a symbolic **Parameter** and let the optimizer find that value for us.

**The Matrix ($A$):**
$$A = 0.5 (Z \otimes Z) + 0.2 (X \otimes X)$$

```{python}
import numpy as np
from qiskit import QuantumCircuit
from qiskit.circuit import Parameter
from qiskit.quantum_info import SparsePauliOp
from qiskit.primitives import StatevectorEstimator
from scipy.optimize import minimize

# Define the Hamiltonian
hamiltonian = SparsePauliOp.from_list([("ZZ", 0.5), ("XX", 0.2)])
print(f"Target Hamiltonian: {hamiltonian}")
```

### Parameterizing the Circuit
In Qiskit, we use `Parameter` objects to create algebraic variables.

```{python}
# 1. Define the Parameters
# These are the "knobs" our classical optimizer will turn.
theta_0 = Parameter('θ0')
theta_1 = Parameter('θ1')

# 2. Build the Circuit
# Instead of fixed angles, we use the parameters.
qc = QuantumCircuit(2)
qc.ry(theta_0, 0) 
qc.ry(theta_1, 1)

print("Parameterized Circuit:")
display(qc.draw("mpl"))
```

### The Cost Function
We need a standard Python function that the optimizer can call. This function takes a list of numbers (the current values of $\vec{\theta}$) and returns a single number (the eigenvalue estimate).

```{python}
estimator = StatevectorEstimator()

def cost_function(params):
    """
    Input: params = [val_0, val_1]
    Output: Expectation Value <v(params)|A|v(params)>
    """
    # Bind the numerical values to the circuit parameters
    pub = (qc, hamiltonian, params)
    
    # Run the job
    job = estimator.run([pub])
    result = job.result()[0]
    
    # Return the scalar float
    return float(result.data.evs)

# Test it with a random guess to make sure it works
test_guess = [0.0, 0.0]
print(f"Value at [0,0]: {cost_function(test_guess):.4f}")
```

### Running the Optimization
We use `scipy.optimize.minimize` with the **COBYLA** method. This is a "gradient-free" optimizer, often used in quantum computing because it handles noise better than standard gradient descent.

```{python}
# 1. Initial Guess
initial_guess = [0.0, 0.0]

print("Starting Optimization...")

# 2. The Minimization Routine
result = minimize(cost_function, initial_guess, method='COBYLA')

# 3. The Output
optimal_angles = result.x
min_eigenvalue = result.fun

print(f"\nOptimization Complete!")
print(f"Optimal Angles found: {optimal_angles}")
print(f"Minimum Eigenvalue found: {min_eigenvalue:.6f}")
```

Success! The optimizer automatically found the angles that produce the minimum eigenvalue.

## 3. Step B: Retrieving the Eigenvector

We have found the minimum eigenvalue ($\lambda_0$), but in many applications (like data science or chemistry), we also need the **eigenvector** itself ($x_0$).

The **Estimator** only gives us the energy. To see the vector structure, we use the **Sampler**.
The Sampler gives us the probability ($P$) of measuring each state. Since $P = |amplitude|^2$, we can reconstruct the magnitude of the state vector.

```{python}
from qiskit.primitives import StatevectorSampler

# 1. Prepare the Circuit for Sampling
qc_sampled = qc.copy()
qc_sampled.measure_all()

# 2. Run the Sampler using the OPTIMAL angles
sampler = StatevectorSampler()
job_sampler = sampler.run([(qc_sampled, optimal_angles)])
result_sampler = job_sampler.result()[0]

# 3. Reconstruct the Vector
# Get counts and convert to probabilities
counts = result_sampler.data.meas.get_counts()
total_shots = sum(counts.values())

# We strictly order the states: |00>, |01>, |10>, |11>
states = ['00', '01', '10', '11']

# Calculate Probabilities
probs = np.array([counts.get(s, 0) / total_shots for s in states])

# Calculate Amplitudes (Sqrt of probability)
quantum_vector = np.sqrt(probs)

print("Reconstructed Quantum Eigenvector:")
print(quantum_vector)
```

### The Moment of Truth: Comparing with Classical Calculation
Did the quantum computer find the correct vector? We can verify this using standard linear algebra tools like `numpy`.

We will construct the matrix $A$ explicitly, diagonalize it, and find the true eigenvector.

```{python}
# 1. Construct the Matrix A Classically
# A = 0.5*ZZ + 0.2*XX
# ZZ = diag(1, -1, -1, 1)
# XX = anti-diag(1, 1, 1, 1)
matrix_A = np.array([
    [0.5, 0,   0,   0.2],
    [0,  -0.5, 0.2, 0  ],
    [0,   0.2,-0.5, 0  ],
    [0.2, 0,   0,   0.5]
])

# 2. Calculate Eigenvalues and Eigenvectors
eigenvals, eigenvecs = np.linalg.eigh(matrix_A)

# 3. Extract the Minimum
# The true ground state for this matrix is roughly [0, 0.707, -0.707, 0]
# This corresponds to the entangled Bell State (|01> - |10>)/sqrt(2)
true_eigenvalue = eigenvals[0]
true_eigenvector = eigenvecs[:, 0]

# 4. Take absolute value for comparison (ignoring phase signs)
true_vector_abs = np.abs(true_eigenvector)

print(f"True Minimum Eigenvalue: {true_eigenvalue:.6f}")
print(f"True Eigenvector:        {true_vector_abs}")
print("-" * 30)
print(f"Quantum Vector Distance: {np.linalg.norm(quantum_vector - true_vector_abs):.6f}")
```

### The Discrepancy: Why didn't it match?
Notice the result above. The **Quantum Vector Distance** is not zero. It is likely quite large (around `0.76`).

The classical calculation reveals that the true ground state is the **Bell State** $\frac{1}{\sqrt{2}}(|01\rangle - |10\rangle)$. This is a **maximally entangled** state.

**Our Ansatz failed.**
We constructed our circuit using only independent rotations (`RY` on qubit 0, `RY` on qubit 1).
$$ |\psi\rangle = (a|0\rangle + b|1\rangle) \otimes (c|0\rangle + d|1\rangle) $$
Mathematically, a tensor product of single qubits can **never** create an entangled state. No matter how much the classical optimizer tuned the angles $\theta_0, \theta_1$, the quantum computer was physically incapable of reaching the solution. It got stuck in the "best possible product state" (likely just $|01\rangle$ or $|10\rangle$), but could not reach the true minimum.

## 4. The Fix: Adding Entanglement

The failure above wasn't an issue with the optimizer; it was an issue with the *Ansatz*. We tried to fit a round peg (an entangled ground state) into a square hole (a product-state circuit).

To fix this, we need to allow the qubits to talk to each other. We do this by adding a **CNOT (CX)** gate after the rotations. This transforms our circuit from a simple tensor product into a state where the value of qubit 1 depends on qubit 0.

### Step C: The Entangled Ansatz

Let's rebuild the circuit, this time appending a `cx(0, 1)` gate.

```{python}
# 1. Define Parameters (Same as before)
theta_0 = Parameter('θ0')
theta_1 = Parameter('θ1')

# 2. Build the Entangled Ansatz
# RY rotations followed by a CNOT entangler
qc_entangled = QuantumCircuit(2)
qc_entangled.ry(theta_0, 0)
qc_entangled.ry(theta_1, 1)
qc_entangled.cx(0, 1)  # <--- The magic ingredient

print("Entangled Ansatz:")
display(qc_entangled.draw("mpl"))
```

### Running the Optimization Again
We use the exact same Hamiltonian ($A$) and the exact same optimizer (COBYLA). The only thing changing is the circuit `qc_entangled`.

```{python}
# Define a new cost function using the entangled circuit
def cost_function_entangled(params):
    # Bind parameters to the NEW circuit
    pub = (qc_entangled, hamiltonian, params)
    job = estimator.run([pub])
    result = job.result()[0]
    return float(result.data.evs)

# Run Optimization
initial_guess = [0.0, 0.0]
result_entangled = minimize(cost_function_entangled, initial_guess, method='COBYLA')

optimal_angles_entangled = result_entangled.x
min_eigenvalue_entangled = result_entangled.fun

print(f"Optimization Complete (Entangled)!")
print(f"Minimum Eigenvalue found: {min_eigenvalue_entangled:.6f}")
print(f"Classical Truth (from Step 3): {true_eigenvalue:.6f}")
```

**The Result:**
With just one added gate, the optimizer should now find a value much closer to the true minimum (approx `-0.70`). The CNOT gate opened up the "Entangled Subspace" of the Hilbert space, allowing the optimizer to access the Bell State solution that was previously impossible to reach. Let us check the correponding eigenvector:

```{python}
from qiskit.primitives import StatevectorSampler

# 1. Prepare the Circuit for Sampling
qc_entangled_sampled = qc_entangled.copy()
qc_entangled_sampled.measure_all()

# 2. Run the Sampler using the OPTIMAL angles
sampler = StatevectorSampler()
job_sampler = sampler.run([(qc_entangled_sampled, optimal_angles_entangled)])
result_sampler = job_sampler.result()[0]

# 3. Reconstruct the Vector
# Get counts and convert to probabilities
counts = result_sampler.data.meas.get_counts()
total_shots = sum(counts.values())

# We strictly order the states: |00>, |01>, |10>, |11>
states = ['00', '01', '10', '11']

# Calculate Probabilities
probs = np.array([counts.get(s, 0) / total_shots for s in states])

# Calculate Amplitudes (Sqrt of probability)
quantum_vector = np.sqrt(probs)

print("Reconstructed Quantum Eigenvector:")
print(quantum_vector)
print(f"Quantum Vector Distance: {np.linalg.norm(quantum_vector - true_vector_abs):.6f}")
```

## 5. The Complications: Why We Can't "Just Scale Up"

In this example, adding one gate solved everything. But what if we have 50 qubits?

It seems obvious: just add rotations and CNOTs everywhere, right? Not quite. This brings us to the theoretical wall of Variational Quantum Algorithms.

To uniquely define an arbitrary quantum state of $N$ qubits, the number of independent real parameters required is:
$$\text{Parameters} = 2(2^N) - 2$$

### The Reality Check: N = 50
Let's look at the numbers for a useful quantum computer:
* **Dimension:** $2^{50} \approx 10^{15}$ (1 Quadrillion states).
* **Parameters Needed:** $\approx 2 \times 10^{15}$.

If we tried to build a "universal" circuit with 1 quadrillion parameters, two things would happen:
1.  **The Quantum Wall:** The circuit would be so deep that noise would destroy the state before we finished preparing it.
2.  **The Classical Wall (Barren Plateaus):** Even with a perfect quantum computer, a classical optimizer cannot handle $10^{15}$ variables. In such a high-dimensional space, the energy landscape becomes essentially flat. The gradient vanishes, and the optimizer gets stuck, having no idea which direction leads "down."

## 6. The Solution: The Ansatz

This is why we cannot simply "parameterize everything." We must be selective.

We cannot search the entire Hilbert space. We must choose a specific **subspace** where we suspect the answer lies. We define a fixed circuit structure—called an **Ansatz** (German for "approach")—that uses a manageable number of parameters (e.g., $N^2$ or even $N$).

$$
|v(\vec{\theta})\rangle = U_{\text{Ansatz}}(\vec{\theta}) |0\dots0\rangle
$$

The "Art" of VQE is designing an Ansatz that is:
1.  **Expressive enough** to capture the physics of the problem (as we saw with the CNOT).
2.  **Simple enough** to be optimized on real hardware.

**Next Steps:** In the next post, we will compare different Ansatz strategies—specifically **Hardware Efficient** circuits vs. **Chemically Inspired** ones (like UCCSD)—to see how we balance accuracy with complexity.