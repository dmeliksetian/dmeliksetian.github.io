{
  "hash": "c49834559dd42cf45cb8221001afd8c4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Encoding Math into Metal: Representing Vectors and Matrices on a QPU\"\ndate: 2025-12-02\ncategories: [Quantum Computing, Qiskit, Linear Algebra]\nimage: img/image_0.png\ndescription: \"How to translate classical linear algebra structures into quantum states and operators, and efficiently calculate expectation values using the Qiskit Estimator.\"\nformat:\n  html:\n    code-fold: show\nexecute:\n  enabled: true\n  freeze: true\n  keep-ipynb: true\njupyter: quantum\n---\n\n\nIn my [previous post](./02-variational-principle.qmd), we established the mathematical goal of VQE: finding a normalized vector $v$ that minimizes the expectation value $v^T A v$.\n\nMathematically, this is elegant. Computationally, it poses a massive storage problem. If our system has $N$ states, $v$ is a vector of size $N$, and $A$ is a matrix of size $N \\times N$. As we scale up, storing these explicitly becomes impossible.\n\nTo solve this on a quantum computer, we need to translate our classical data structures into quantum mechanics. We need to answer two fundamental questions:\n\n1.  How do we represent a high-dimensional vector $v$ on a quantum processor?\n2.  How do we represent the matrix $A$ so we can calculate its expectation value?\n\n## 1. Representing an N-dimensional Vector\n\nIn the classical world, if I want to store a state vector $v$ of size $N=4$, I allocate an array of 4 floating-point numbers in memory:\n\n$$\nv_{classical} = \\begin{bmatrix} v_0 \\\\ v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix}\n$$\n\nThe memory requirement grows linearly with $N$. However, in quantum problems, $N$ represents the dimension of the Hilbert space, which grows **exponentially** with the number of particles or qubits ($N = 2^n$).\n\n### The Quantum Compression\nOn a quantum computer, we use **Amplitude Encoding**. We map the **indices** of the vector to the **computational basis states** of our qubits.\n\nTo represent a vector of size $N$, we need only $n = \\log_2(N)$ qubits.\nFor our $N=4$ example, we need just $n=2$ qubits. The indices $0, 1, 2, 3$ correspond to the binary states $|00\\rangle, |01\\rangle, |10\\rangle, |11\\rangle$.\n\nThe vector $v$ is then represented as the **superposition state** of the quantum system:\n\n$$\n|v\\rangle = v_0|00\\rangle + v_1|01\\rangle + v_2|10\\rangle + v_3|11\\rangle\n$$\n\n### The Constraint: Normalization\nThere is one strict constraint. In classical coding, a vector can have any magnitude. In quantum mechanics, probabilities must sum to 1. Therefore, the vector $|v\\rangle$ must be normalized such that the sum of the squared absolute values of its coefficients equals 1:\n\n$$\n\\sum_{i=0}^{N-1} |v_i|^2 = 1\n$$\n\nThis means that our quantum state $|v\\rangle$ is mathematically identical to the normalized vector $v$ we discussed in the previous post. We aren't \"storing\" the numbers $v_i$ in digital memory addresses; the numbers $v_i$ exist physically as the probability amplitudes of the wavefunction itself.\n\n## 2. Representing the NxN Matrix\n\nNow, what about the matrix $A$?\nClassically, $A$ is a dense grid of numbers. If the vector has dimension $N=2^n$, the matrix has $(2^n)^2$ entries. Storing a matrix for just 50 qubits would require more memory than exists on Earth.\n\nIn the quantum context, $A$ represents an observable (usually a Hamiltonian). We do not store this matrix in the quantum computer's memory. Instead, we represent it in the native language of the quantum processor: **Pauli Strings**.\n\n### The Decomposition\nThe set of Pauli matrices $\\{I, X, Y, Z\\}$ forms a complete basis for the space of $2 \\times 2$ Hermitian matrices. For a multi-qubit system, we use tensor products of these matrices (e.g., $Z \\otimes Z$ or $X \\otimes I$).\n\nAny Hermitian matrix $A$ can be written as a weighted sum of these Pauli strings:\n\n$$\nA = \\sum_{j} c_j P_j\n$$\n\nWhere $c_j$ are real-valued scalar coefficients and $P_j$ are Pauli strings.\n\n### A Crucial Detail: Where do these strings come from?\nYou might be asking: *\"If the matrix $A$ is too big to store, how do we calculate this decomposition?\"*\n\nThere are two scenarios:\n\n1.  **The Mathematical Route:** If we *did* have a small arbitrary matrix, we could mathematically decompose it using the **Hilbert-Schmidt inner product**. We project the matrix onto each Pauli basis tensor to find the coefficients $c_j$. However, doing this for large $N$ defeats the purpose, as we would need to build the giant matrix first.\n\n2.  **The Practical Route (Direct Mapping):** In useful quantum applications (like Chemistry or Optimization), **we never build the dense matrix**.\n    * **In Chemistry:** The interaction between electrons is described by the **Jordan-Wigner** or **Bravyi-Kitaev** transformations, which map the physical system *directly* into a sum of Pauli strings ($O(n^4)$ terms) without ever creating a $2^n \\times 2^n$ array.\n    * **In Optimization (MaxCut):** The cost function of a graph cut maps directly to a sum of $Z_i Z_j$ terms based on the graph's edges.\n\nThis allows us to work with operators for 50+ qubits (a vector space of $10^{15}$) while only storing a polynomial number of Pauli terms in our laptop's memory.\n\n> **Note:** If these transformations sound complex, don't worry. We will dedicate a future post in this series specifically to **Problem Mapping**â€”showing exactly how to turn a physical chemistry problem or a logistics graph into these Pauli strings without ever building the giant matrix.\n\n### Why This Solves the Complexity Problem\nThis representation changes the problem from \"massive matrix multiplication\" to \"linear summation.\"\n\nRecall that we want to calculate the expectation value $\\langle v | A | v \\rangle$. Using the linearity of expectation, we can break this down:\n\n$$\n\\langle v | A | v \\rangle = \\langle v | \\left( \\sum_j c_j P_j \\right) | v \\rangle = \\sum_j c_j \\langle v | P_j | v \\rangle\n$$\n\nThis is the key to the efficiency of the algorithm. We don't need a quantum computer that can \"process\" the giant matrix $A$ all at once. We only need a quantum computer that can measure simple Pauli terms.\n\n## 3. Calculating the Expectation Value\n\nWe have defined our vector $|v\\rangle$ and decomposed our matrix $A$. Now comes the actual computation: calculating $\\langle v | P_j | v \\rangle$. How do we actually ask a quantum computer for this number?\n\n### A) The Manual Approach: Sampling Eigenvalues\n\nLet's assume our Hamiltonian is just a single Pauli string, say $Z$ on a single qubit. The expectation value is simply the weighted average of outcomes.\nWe run the circuit, measure the qubit, and collect the bitstrings (e.g., `0`, `0`, `1`, `0`...). mapping `0` to $+1$ and `1` to $-1$.\n\n**Why this mapping?**\nThis isn't arbitrary. It relies on the known spectral properties of Pauli matrices.\nThe computational basis states $|0\\rangle$ and $|1\\rangle$ are the **eigenstates** of the Pauli $Z$ operator, with eigenvalues $+1$ and $-1$ respectively:\n\n$$Z|0\\rangle = (+1)|0\\rangle$$\n$$Z|1\\rangle = (-1)|1\\rangle$$\n\nWhen we measure a qubit, we are collapsing it into one of these eigenstates. The value we associate with that outcome is the corresponding eigenvalue.\n\n**Extending to Multi-Qubit Terms**\nCrucially, the eigenvalue of a tensor product of Pauli matrices is simply the **product** of the eigenvalues of each individual matrix.\n\nFor example, if we are measuring the operator $Z \\otimes Z$ on two qubits and we observe the state $|01\\rangle$:\n* The first qubit is in $|0\\rangle$ (eigenvalue $+1$).\n* The second qubit is in $|1\\rangle$ (eigenvalue $-1$).\n* The total eigenvalue for this shot is $(+1) \\times (-1) = -1$.\n\nThis allows us to reconstruct the value of any complex Pauli string simply by multiplying the results of individual qubit measurements.\n\n$$\\langle Z \\rangle \\approx \\frac{(+1) \\cdot N_0 + (-1) \\cdot N_1}{N_{total}}$$\n\n**What about X and Y?**\nQuantum hardware generally only measures in the **Z-basis**. If our Pauli string contains an $X$ or $Y$, we cannot measure it directly. We must apply a basis rotation gate (like a Hadamard for $X$) *just before* measurement to align the axis with $Z$.\n\n### B) The Challenge: The Explosion of Terms\n\nIn a real problem, our matrix $A$ might contain **thousands** of Pauli terms.\n\n$$H = c_1 (Z_0 Z_1) + c_2 (X_0 X_1) + c_3 (Z_0 I_1) + \\dots$$\n\nIf we were to run a separate quantum experiment (Sampler job) for every single term, the overhead would be astronomical.\n\n**The Solution: Operator Grouping**\nFortunately, we can exploit **commutativity**.\nIf two Pauli strings commute (specifically, qubit-wise commutativity), they can be measured in the same basis simultaneously.\n\nFor example, $Z_0 Z_1$ and $Z_0 I_1$ both require the Z-basis. We can measure both in a single \"shot\".\nHowever, $Z_0 Z_1$ and $X_0 X_1$ do **not** commute (Heisenberg's Uncertainty Principle). You cannot measure Z and X on qubit 0 at the same time.\n\nTherefore, we group the thousands of Pauli strings into a small number of **commuting families**. We run one quantum job per family, effectively compressing thousands of measurements into a few dozen jobs.\n\n### C) The Abstraction: The Qiskit Estimator\n\nDoing this efficiently involves significant bookkeeping: checking commutativity, grouping terms, appending rotations, and aggregating statistics.\n\nIn modern Qiskit, this is abstracted away by the **Estimator**. The Estimator is a primitive that takes the Circuit (state) and the Operator (matrix), handles the grouping and rotations internally, and returns the final floating-point expectation value.\n\n\n## 4. Code Example: The Estimator in Action\nLet's make this concrete. We will not start with quantum gates; we will start with a standard linear algebra problem.\n\n**The Classical Problem**\nImagine we have a $4 \\times 4$ Hermitian matrix $A$ and a 4-dimensional vector $v$, and we want to calculate $v^T A v$.\n\n$$\nA = \\begin{bmatrix} \n0.5 & 0 & 0 & 0.2 \\\\ \n0 & -0.5 & 0.2 & 0 \\\\ \n0 & 0.2 & -0.5 & 0 \\\\ \n0.2 & 0 & 0 & 0.5 \n\\end{bmatrix}\n$$\n\nWe want to verify the expectation value for a specific normalized vector:\n$$\nv \\approx \\begin{bmatrix} 0.80 \\\\ 0.46 \\\\ 0.33 \\\\ 0.19 \\end{bmatrix}\n$$\n\nThis problem is so small that one could do this on paper to determine that $v^T A v \\approx 0.299$. However, we are going to use this example to illustrate how this problem can be mapped to a quantum system and how it produces an output.\n\n**1. The Matrix Decomposition:**\nWe cannot load the $4 \\times 4$ array into the QPU. We must break it down.\nLooking at the structure of $A$:\n* The diagonal terms correspond to $Z \\otimes Z$.\n* The off-diagonal terms correspond to $X \\otimes X$.\n\nWe can rewrite $A$ exactly as:\n$$A = 0.5 (Z \\otimes Z) + 0.2 (X \\otimes X)$$\n\n**2. The Vector Construction:**\nQuantum computers always start in the $|00\\rangle$ state (the vector $[1, 0, 0, 0]$). We need to build a circuit to transform this into our target vector $v$.\nWe can do this using $R_Y$ (Rotation-Y) gates.\n\n* Applying $R_Y(\\pi/3)$ to qubit 0 creates amplitudes $\\approx [0.866, 0.5]$.\n* Applying $R_Y(\\pi/4)$ to qubit 1 creates amplitudes $\\approx [0.924, 0.383]$.\n\nThe tensor product of these rotations results in exactly our target vector $[0.80, 0.46, 0.33, 0.19]$.\n\n### The Quantum Code\nNow, let's write the code to implement this mapping and verify the result matches our classical calculation.\n\n\n\n::: {#8d534ba2 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nfrom qiskit import QuantumCircuit\nfrom qiskit.quantum_info import SparsePauliOp\nfrom qiskit.primitives import StatevectorEstimator\n\n# 1. The Matrix A (The Hamiltonian)\n# We define A = 0.5 * (Z on q0, Z on q1) + 0.2 * (X on q0, X on q1)\nhamiltonian = SparsePauliOp.from_list([\n    (\"ZZ\", 0.5),  \n    (\"XX\", 0.2)   \n])\n\nprint(\"Operator A:\", end=\" \")\nprint_hamiltonian(hamiltonian)\nprint(\"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOperator A: 0.50 * ZZ + 0.20 * XX\n\n\n```\n:::\n:::\n\n\n::: {#629de96b .cell execution_count=3}\n``` {.python .cell-code}\n# 2. The Vector |v> (State Preparation)\n# We use Ry gates to rotate the qubits from |0> to a superposition.\n# using real-valued rotations keeps the amplitudes real.\nqc = QuantumCircuit(2)\nqc.ry(np.pi/3, 0) # Rotate qubit 0 by 60 degrees\nqc.ry(np.pi/4, 1) # Rotate qubit 1 by 45 degrees\n\nprint(\"Circuit representing state |v>:\")\ndisplay(qc.draw(\"mpl\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCircuit representing state |v>:\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](03-encoding-math-into-metal_files/figure-html/cell-4-output-2.png){width=170 height=168}\n:::\n:::\n\n\n::: {#876f9e03 .cell execution_count=4}\n``` {.python .cell-code}\n# 3. The Abstraction (The Estimator)\n# We instantiate the local StatevectorEstimator\nestimator = StatevectorEstimator()\n\n# The estimator handles the basis rotations and operator grouping internally.\n# Run format: run([(circuit, operator)])\njob = estimator.run([(qc, hamiltonian)])\nresult = job.result()[0]\n\n# 4. The Result\n# result.data.evs is a NumPy array of expectation values.\n# We access the first element [0] to get our specific scalar result.\nexpectation_value = result.data.evs\n\nprint(f\"\\nCalculated Expectation Value <v|A|v>: {expectation_value:.6f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCalculated Expectation Value <v|A|v>: 0.299251\n```\n:::\n:::\n\n\n**What just happened?**\nThe Estimator acted as our \"Linear Algebra Calculator.\"\n\n1.  **Input:** It took a Circuit (a recipe for creating the vector $v$) and an Operator (the decomposition of matrix $A$).\n2.  **Process:** It handled the basis rotations and measurements internally (splitting ZZ and XX into different measurement jobs if needed).\n3.  **Output:** It returned the scalar value $v^T A v$.\n\n**Next Steps:** In the next post, we will finally close the loop. We will replace our fixed manual angles with **variables**, introducing the **Ansatz**, and use a classical optimization algorithm to find the specific angles that minimize our energy.\n\n",
    "supporting": [
      "03-encoding-math-into-metal_files"
    ],
    "filters": [],
    "includes": {}
  }
}